{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd112a18144ee0f",
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b888b40-6274-4d1d-acb2-0e27a7074d3a",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import psutil\n",
    "import shutil\n",
    "\n",
    "\n",
    "def get_disk_usage(path=\".\"):\n",
    "    total, used, free = shutil.disk_usage(path)\n",
    "    return {\n",
    "        'total_gb': total / 1024**3,\n",
    "        'used_gb': used / 1024**3,\n",
    "        'free_gb': free / 1024**3,\n",
    "        'used_percent': (used / total) * 100\n",
    "    }\n",
    "\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"Memory Usage\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / 1024 / 1024 / 1024\n",
    "\n",
    "\n",
    "def initialize_gpu_safe():\n",
    "\n",
    "    try:\n",
    "        if not cp.cuda.is_available():\n",
    "            return False\n",
    "        \n",
    "        device = cp.cuda.Device(0)\n",
    "        mem_info = device.mem_info\n",
    "        free_gb = mem_info[1] / 1024**3\n",
    "        \n",
    "        if free_gb < 5:\n",
    "            print(f\"GPU memory insufficient: {free_gb:.1f}GB\")\n",
    "            return False\n",
    "        \n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        mempool.set_limit(size=int(free_gb * 0.6 * 1024**3))\n",
    "        \n",
    "        print(f\"GPU initialized, memory limit: {free_gb * 0.6:.1f}GB\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"GPU init failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def force_cleanup():\n",
    "    \"\"\"Clear memory\"\"\"\n",
    "    try:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "    except:\n",
    "        pass\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def get_raster_info(raster_file):\n",
    "    try:\n",
    "        with rasterio.open(raster_file) as src:\n",
    "            # first band\n",
    "            band = src.read(1, window=((0, 1), (0, 1)))  # Obtain data type through the first pixel\n",
    "            \n",
    "            info = {\n",
    "                'shape': src.shape,\n",
    "                'dtype': band.dtype,\n",
    "                'nodata': src.nodata,\n",
    "                'transform': src.transform,\n",
    "                'crs': src.crs,\n",
    "                'bounds': src.bounds\n",
    "            }\n",
    "            return info\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting info for {raster_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_chunk_fixed(chunk_data, transform, start_row, nodata_value, use_gpu=True):\n",
    "    try:\n",
    "        rows, cols = chunk_data.shape\n",
    "        \n",
    "        if nodata_value is not None:\n",
    "            # Effective data to avoid Nodata\n",
    "            valid_mask = chunk_data != nodata_value\n",
    "        else:\n",
    "            # Assuming 0 is an invalid value without nodata\n",
    "            valid_mask = chunk_data != 0\n",
    "        \n",
    "        # 检查是否有有效数据\n",
    "        if not np.any(valid_mask):\n",
    "            return {}\n",
    "        \n",
    "        if use_gpu and cp.cuda.is_available():\n",
    "            return process_chunk_gpu_fixed(chunk_data, transform, start_row, valid_mask)\n",
    "        else:\n",
    "            return process_chunk_cpu_fixed(chunk_data, transform, start_row, valid_mask)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def process_chunk_gpu_fixed(chunk_data, transform, start_row, valid_mask):\n",
    "    \"\"\"GPU process chunk\"\"\"\n",
    "    try:\n",
    "        # GPU Memory Usage\n",
    "        device = cp.cuda.Device(0)\n",
    "        free_gb = device.mem_info[1] / 1024**3\n",
    "        estimated_mem = (chunk_data.size * 4 * 3) / 1024**3\n",
    "        \n",
    "        if estimated_mem > free_gb * 0.8:\n",
    "            return process_chunk_cpu_fixed(chunk_data, transform, start_row, valid_mask)\n",
    "        \n",
    "        row_idx, col_idx = np.where(valid_mask)\n",
    "        values = chunk_data[valid_mask]\n",
    "        \n",
    "        row_idx_gpu = cp.asarray(row_idx + start_row)\n",
    "        col_idx_gpu = cp.asarray(col_idx)\n",
    "        \n",
    "        x_coords = transform[0] + col_idx_gpu * transform[1] + row_idx_gpu * transform[2]\n",
    "        y_coords = transform[3] + col_idx_gpu * transform[4] + row_idx_gpu * transform[5]\n",
    "        \n",
    "        x_coords_cpu = cp.asnumpy(x_coords)\n",
    "        y_coords_cpu = cp.asnumpy(y_coords)\n",
    "        \n",
    "        del row_idx_gpu, col_idx_gpu, x_coords, y_coords\n",
    "        force_cleanup()\n",
    "        \n",
    "        result = {(x, y): val for x, y, val in zip(x_coords_cpu, y_coords_cpu, values)}\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"GPU processing failed: {e}\")\n",
    "        force_cleanup()\n",
    "        return process_chunk_cpu_fixed(chunk_data, transform, start_row, valid_mask)\n",
    "\n",
    "\n",
    "def process_chunk_cpu_fixed(chunk_data, transform, start_row, valid_mask):\n",
    "    \"\"\"CPU process chunk\"\"\"\n",
    "    try:\n",
    "        row_idx, col_idx = np.where(valid_mask)\n",
    "        values = chunk_data[valid_mask]\n",
    "        \n",
    "        global_row_idx = row_idx + start_row\n",
    "        \n",
    "        x_coords = transform[0] + col_idx * transform[1] + global_row_idx * transform[2]\n",
    "        y_coords = transform[3] + col_idx * transform[4] + global_row_idx * transform[5]\n",
    "        \n",
    "        result = {(x, y): val for x, y, val in zip(x_coords, y_coords, values)}\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"CPU processing failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def process_raster_file_fixed(raster_file, raster_name, use_gpu=True, chunk_size=512):\n",
    "    \"\"\"修复后的栅格文件处理\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {raster_name}\")\n",
    "    \n",
    "    # 获取栅格信息\n",
    "    raster_info = get_raster_info(raster_file)\n",
    "    if not raster_info:\n",
    "        return {}\n",
    "    \n",
    "    rows, cols = raster_info['shape']\n",
    "    transform = raster_info['transform']\n",
    "    nodata_value = raster_info['nodata']\n",
    "    \n",
    "    print(f\"Dimensions: {rows}x{cols}\")\n",
    "    print(f\"NoData value: {nodata_value}\")\n",
    "    print(f\"Chunk size: {chunk_size}\")\n",
    "    \n",
    "    coordinate_data = {}\n",
    "    total_chunks = (rows + chunk_size - 1) // chunk_size\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(raster_file) as src:\n",
    "            with tqdm(total=total_chunks, desc=f\"Processing {raster_name}\", unit=\"chunk\") as pbar:\n",
    "                for chunk_idx in range(total_chunks):\n",
    "                    start_row = chunk_idx * chunk_size\n",
    "                    end_row = min(start_row + chunk_size, rows)\n",
    "                    \n",
    "                    chunk_data = src.read(1, window=((start_row, end_row), (0, cols)))\n",
    "                    \n",
    "                    chunk_result = process_chunk_fixed(\n",
    "                        chunk_data, transform, start_row, nodata_value, use_gpu\n",
    "                    )\n",
    "                    \n",
    "                    coordinate_data.update(chunk_result)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix({\n",
    "                        'coords': f\"{len(coordinate_data):,}\",\n",
    "                        'mem': f\"{get_memory_usage():.1f}GB\"\n",
    "                    })\n",
    "                    \n",
    "                    if chunk_idx % 20 == 0:\n",
    "                        force_cleanup()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {raster_name}: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"✓ {raster_name} completed: {len(coordinate_data):,} coordinates\")\n",
    "    return coordinate_data\n",
    "\n",
    "\n",
    "def build_dataset_final_fixed(raster_files, output_txt=\"final_output.txt\", use_gpu=True, chunk_size=512):\n",
    "    \"\"\"Final version dataset construction\"\"\"\n",
    "    \n",
    "    disk_info = get_disk_usage()\n",
    "    print(f\"Disk Space - Free: {disk_info['free_gb']:.1f}GB\")\n",
    "    \n",
    "    raster_names = [os.path.splitext(os.path.basename(f))[0] for f in raster_files]\n",
    "    \n",
    "    gpu_available = False\n",
    "    if use_gpu:\n",
    "        gpu_available = initialize_gpu_safe()\n",
    "    \n",
    "    processing_mode = \"GPU\" if gpu_available else \"CPU\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FINAL FIXED PROCESSING\")\n",
    "    print(f\"Files: {raster_names}\")\n",
    "    print(f\"Mode: {processing_mode}\")\n",
    "    print(f\"Chunk size: {chunk_size}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # 存储所有坐标数据\n",
    "    all_coordinates = {}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for file_idx, (raster_file, raster_name) in enumerate(zip(raster_files, raster_names)):\n",
    "        print(f\"\\n[{file_idx+1}/{len(raster_files)}] Processing {raster_name}\")\n",
    "        \n",
    "        file_coordinates = process_raster_file_fixed(\n",
    "            raster_file, raster_name, gpu_available, chunk_size\n",
    "        )\n",
    "        \n",
    "        for coord, value in file_coordinates.items():\n",
    "            if coord not in all_coordinates:\n",
    "                all_coordinates[coord] = [0] * len(raster_files)\n",
    "            all_coordinates[coord][file_idx] = value\n",
    "        \n",
    "        print(f\"File {file_idx+1} processed: {len(file_coordinates):,} coordinates\")\n",
    "        print(f\"Total unique coordinates: {len(all_coordinates):,}\")\n",
    "        \n",
    "        del file_coordinates\n",
    "        force_cleanup()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"WRITING OUTPUT FILE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        with open(output_txt, 'w') as f:\n",
    "\n",
    "            f.write(\"Longitude Latitude \" + \" \".join(raster_names) + \"\\n\")\n",
    "            \n",
    "            with tqdm(total=len(all_coordinates), desc=\"Writing output\", unit=\"row\") as pbar:\n",
    "                for coord, values in all_coordinates.items():\n",
    "                    x, y = coord\n",
    "                    line = f\"{x} {y} \" + \" \".join(map(str, values)) + \"\\n\"\n",
    "                    f.write(line)\n",
    "                    pbar.update(1)\n",
    "        \n",
    "        output_size = os.path.getsize(output_txt) / 1024**3\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing output: {e}\")\n",
    "        return False\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total time: {total_time/60:.1f} minutes\")\n",
    "    print(f\"Coordinates processed: {len(all_coordinates):,}\")\n",
    "    print(f\"Output file: {output_txt}\")\n",
    "    print(f\"Output size: {output_size:.3f}GB\")\n",
    "    print(f\"Processing mode: {processing_mode}\")\n",
    "    print(f\"Success: ✓\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    raster_files = [\n",
    "        \"c:/NC_data/resample_file/Trans01_20_12_Reclass1.tif\",\n",
    "        \"c:/NC_data/resample_file/intersec_koppen.tif\"\n",
    "    ]\n",
    "    \n",
    "    # 运行修复后的版本\n",
    "    success = build_dataset_final_fixed(\n",
    "        raster_files,\n",
    "        output_txt=\"c:/NC_data/processed_data_2.txt\"\n",
    "        use_gpu=True,\n",
    "        chunk_size=256  # 保守的chunk size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5799d1d2-80e8-4753-808e-b4cd3f837ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
